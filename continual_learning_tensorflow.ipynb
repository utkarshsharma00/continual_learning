{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "continual_learning_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-ZCw2agYEs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "9a74c102-d669-4de9-ea61-99590a04c5f4"
      },
      "source": [
        "'''\n",
        "Starts with just 3 classes, trains for 10 epochs then \n",
        "incrementally trains the rest of the classes by reusing \n",
        "the trained weights.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1)  # for reproducibility\n",
        "from keras import backend as K\n",
        "K.common.image_dim_ordering() == 'th'\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtgJWceI8N_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_data(classes, total_classes, X_train_all, y_train_all, X_test_all,\n",
        "               y_test_all):\n",
        "    train_ind = []\n",
        "    test_ind = []\n",
        "    for c in classes:\n",
        "        train_ind.extend(list(np.where(y_train_all == c)[0]))\n",
        "        test_ind.extend(list(np.where(y_test_all == c)[0]))\n",
        "\n",
        "    X_train = X_train_all[train_ind, :, :]\n",
        "    X_test = X_test_all[test_ind, :, :]\n",
        "\n",
        "    y_train_true = y_train_all[train_ind]\n",
        "    y_train = np.zeros(y_train_true.shape)\n",
        "    y_test_true = y_test_all[test_ind]\n",
        "    y_test = np.zeros(y_test_true.shape)\n",
        "\n",
        "    for i, c in enumerate(classes):\n",
        "        train_ind = list(np.where(y_train_true == c)[0])\n",
        "        test_ind = list(np.where(y_test_true == c)[0])\n",
        "        y_train[train_ind] = i\n",
        "        y_test[test_ind] = i\n",
        "\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "    X_train /= 255\n",
        "    X_test /= 255\n",
        "\n",
        "    # converting class vectors to binary class matrices\n",
        "    Y_train = np_utils.to_categorical(y_train, total_classes)\n",
        "    Y_test = np_utils.to_categorical(y_test, total_classes)\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5myZjDC8SvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(old_model=None):\n",
        "    model = Sequential()\n",
        "\n",
        "    if old_model is None:\n",
        "        model.add(\n",
        "            Convolution2D(32, (3, 3),\n",
        "                          input_shape=(1, 28, 28),\n",
        "                          data_format='channels_first'))\n",
        "    else:\n",
        "        weights = old_model.layers[0].get_weights()\n",
        "        model.add(\n",
        "            Convolution2D(32, (3, 3),\n",
        "                          weights=weights,\n",
        "                          input_shape=(1, 28, 28),\n",
        "                          data_format='channels_first'))\n",
        "\n",
        "    model.add(Activation('relu'))\n",
        "    if old_model is None:\n",
        "        model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
        "    else:\n",
        "        weights = old_model.layers[2].get_weights()\n",
        "        model.add(Convolution2D(nb_filters, nb_conv, nb_conv, weights=weights))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    if old_model is None:\n",
        "        model.add(Dense(128))\n",
        "    else:\n",
        "        weights = old_model.layers[7].get_weights()\n",
        "        model.add(Dense(128, weights=weights))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIAe439l8ZmN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "411799dd-2936-47f7-90af-a94be14e6bcc"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    MODEL_TRAINED = False\n",
        "    # input image dimensions\n",
        "    img_rows, img_cols = 28, 28\n",
        "\n",
        "    # the data, shuffling and splitting between training and testing sets\n",
        "    (X_train_all, y_train_all), (X_test_all, y_test_all) = mnist.load_data()\n",
        "\n",
        "    if not MODEL_TRAINED:\n",
        "        batch_size = 256\n",
        "        total_classes = 10\n",
        "        nb_epoch = 10\n",
        "\n",
        "        # number of convolutional filters to use\n",
        "        nb_filters = 32\n",
        "        # size of pooling area for max pooling\n",
        "        nb_pool = 2\n",
        "        # convolution kernel size\n",
        "        nb_conv = 3\n",
        "\n",
        "        classes = [9, 1, 6]\n",
        "        X_train, Y_train, X_test, Y_test = build_data(classes, 3, X_train_all,\n",
        "                                                      y_train_all, X_test_all,\n",
        "                                                      y_test_all)\n",
        "\n",
        "        model1 = build_model()\n",
        "        model1.add(Dense(len(classes)))\n",
        "        model1.add(Activation('softmax'))\n",
        "        model1.compile(loss='categorical_crossentropy',\n",
        "                       optimizer='adadelta',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "        model1.fit(X_train,\n",
        "                   Y_train,\n",
        "                   batch_size=batch_size,\n",
        "                   epochs=nb_epoch,\n",
        "                   verbose=2,\n",
        "                   validation_data=(X_test, Y_test))\n",
        "\n",
        "        # Saving this model for further imvestigation\n",
        "        json_string = model1.to_json()\n",
        "        open('model1_incremental_architecture.json', 'w').write(json_string)\n",
        "        model1.save_weights('model1_incremental_weights.h5')\n",
        "\n",
        "        score = model1.evaluate(X_test, Y_test, verbose=0)\n",
        "        print('Test score:', score[0])\n",
        "        print('Test accuracy:', score[1])\n",
        "\n",
        "        '''Now creating a new model with all total_classes in the softmax layer.\n",
        "        Copying over the weights to this new network and initializing the new class connections randomly.'''\n",
        "        model2 = build_model(old_model=model1)\n",
        "        model2.add(Dense(total_classes))\n",
        "\n",
        "        # Replacing the corresponding weights of the new network with the previously trained class weights\n",
        "        weights = model2.layers[-1].get_weights()\n",
        "        old_weights = model1.layers[-2].get_weights()  # Last dense layer is second to last layer\n",
        "        weights[0][:, -len(classes):] = old_weights[0]\n",
        "        weights[1][-len(classes):] = old_weights[1]\n",
        "        model2.layers[-1].set_weights(weights)\n",
        "        model2.add(Activation('softmax'))\n",
        "        model2.compile(loss='categorical_crossentropy',\n",
        "                       optimizer='adadelta',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "        new_classes = [7, 0, 3, 5, 2, 8, 4]\n",
        "        class_mapping = new_classes[:]\n",
        "        class_mapping.extend(classes)\n",
        "        X_train, Y_train, X_test, Y_test = build_data(new_classes, 10,\n",
        "                                                      X_train_all, y_train_all,\n",
        "                                                      X_test_all, y_test_all)\n",
        "\n",
        "        model2.fit(X_train,\n",
        "                   Y_train,\n",
        "                   batch_size=batch_size,\n",
        "                   epochs=nb_epoch,\n",
        "                   verbose=2,\n",
        "                   validation_data=(X_test, Y_test))\n",
        "        score = model2.evaluate(X_test, Y_test, verbose=0)\n",
        "        print('Test score:', score[0])\n",
        "        print('Test accuracy:', score[1])\n",
        "\n",
        "        # Saving the incrementally trained model\n",
        "        json_string = model2.to_json()\n",
        "        open('model2_incremental_architecture.json', 'w').write(json_string)\n",
        "        model2.save_weights('model2_incremental_weights.h5')\n",
        "\n",
        "        X_test = X_test_all.reshape(X_test_all.shape[0], 1, img_rows, img_cols)\n",
        "        X_test = X_test.astype('float32')\n",
        "        X_test /= 255\n",
        "\n",
        "        # Converting class vectors to binary class matrices.\n",
        "        '''NOTE\n",
        "        When a new image is presented to this network, the label of the image must be\n",
        "        fed into class_mapping to get the \"real\" label of the output'''\n",
        "    \n",
        "        y_test = np.array([class_mapping.index(c) for c in y_test_all])\n",
        "        Y_test = np_utils.to_categorical(y_test, total_classes)\n",
        "\n",
        "        score = model2.evaluate(X_test, Y_test, verbose=1)\n",
        "        print('Total Test score:', score[0])\n",
        "        print('Total Test accuracy:', score[1])\n",
        "\n",
        "    else:\n",
        "        # Loading the incrementally trained model and testing it\n",
        "        model = model_from_json(\n",
        "            open('model2_incremental_architecture.json').read())\n",
        "        model.load_weights('model2_incremental_weights.h5')\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer='adadelta',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        classes = [7, 0, 3, 5, 2, 8, 4, 9, 1, 6]\n",
        "        X_train, Y_train, X_test, Y_test = build_data(classes, 10, X_train_all,\n",
        "                                                      y_train_all, X_test_all,\n",
        "                                                      y_test_all)\n",
        "\n",
        "        score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "        print('Total Test score:', score[0])\n",
        "        print('Total Test accuracy:', score[1])\n",
        "\n",
        "        score = model.evaluate(X_train, Y_train, verbose=1)\n",
        "        print('Total Train score:', score[0])\n",
        "        print('Total Train accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 18609 samples, validate on 3102 samples\n",
            "Epoch 1/10\n",
            " - 37s - loss: 0.1445 - acc: 0.9452 - val_loss: 0.0354 - val_acc: 0.9903\n",
            "Epoch 2/10\n",
            " - 37s - loss: 0.0321 - acc: 0.9911 - val_loss: 0.0330 - val_acc: 0.9913\n",
            "Epoch 3/10\n",
            " - 36s - loss: 0.0248 - acc: 0.9918 - val_loss: 0.0201 - val_acc: 0.9942\n",
            "Epoch 4/10\n",
            " - 36s - loss: 0.0188 - acc: 0.9942 - val_loss: 0.0172 - val_acc: 0.9948\n",
            "Epoch 5/10\n",
            " - 36s - loss: 0.0159 - acc: 0.9951 - val_loss: 0.0185 - val_acc: 0.9939\n",
            "Epoch 6/10\n",
            " - 36s - loss: 0.0137 - acc: 0.9957 - val_loss: 0.0159 - val_acc: 0.9952\n",
            "Epoch 7/10\n",
            " - 36s - loss: 0.0127 - acc: 0.9953 - val_loss: 0.0153 - val_acc: 0.9955\n",
            "Epoch 8/10\n",
            " - 36s - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0150 - val_acc: 0.9952\n",
            "Epoch 9/10\n",
            " - 36s - loss: 0.0107 - acc: 0.9966 - val_loss: 0.0125 - val_acc: 0.9955\n",
            "Epoch 10/10\n",
            " - 37s - loss: 0.0087 - acc: 0.9969 - val_loss: 0.0127 - val_acc: 0.9961\n",
            "Test score: 0.012719842892324869\n",
            "Test accuracy: 0.996131527777413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), weights=[array([[[...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 41391 samples, validate on 6898 samples\n",
            "Epoch 1/10\n",
            " - 80s - loss: 0.4552 - acc: 0.8661 - val_loss: 0.1322 - val_acc: 0.9584\n",
            "Epoch 2/10\n",
            " - 80s - loss: 0.1505 - acc: 0.9540 - val_loss: 0.0659 - val_acc: 0.9781\n",
            "Epoch 3/10\n",
            " - 80s - loss: 0.1024 - acc: 0.9695 - val_loss: 0.0514 - val_acc: 0.9816\n",
            "Epoch 4/10\n",
            " - 81s - loss: 0.0786 - acc: 0.9766 - val_loss: 0.0410 - val_acc: 0.9852\n",
            "Epoch 5/10\n",
            " - 81s - loss: 0.0644 - acc: 0.9802 - val_loss: 0.0370 - val_acc: 0.9867\n",
            "Epoch 6/10\n",
            " - 80s - loss: 0.0572 - acc: 0.9831 - val_loss: 0.0294 - val_acc: 0.9901\n",
            "Epoch 7/10\n",
            " - 80s - loss: 0.0490 - acc: 0.9852 - val_loss: 0.0381 - val_acc: 0.9864\n",
            "Epoch 8/10\n",
            " - 80s - loss: 0.0449 - acc: 0.9870 - val_loss: 0.0311 - val_acc: 0.9884\n",
            "Epoch 9/10\n",
            " - 80s - loss: 0.0393 - acc: 0.9877 - val_loss: 0.0271 - val_acc: 0.9901\n",
            "Epoch 10/10\n",
            " - 80s - loss: 0.0359 - acc: 0.9887 - val_loss: 0.0260 - val_acc: 0.9904\n",
            "Test score: 0.025968390050783035\n",
            "Test accuracy: 0.9904320092780516\n",
            "10000/10000 [==============================] - 5s 531us/step\n",
            "Total Test score: 3.3523174530029296\n",
            "Total Test accuracy: 0.6832\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}